<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="个人笔记"><title>6.kafka Consumer配置 | 记忆不靠谱</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><meta name="generator" content="Hexo 4.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">6.kafka Consumer配置</h1><a id="logo" href="/.">记忆不靠谱</a><p class="description">人生很奇妙，过好每一天</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">6.kafka Consumer配置</h1><div class="post-meta">Jul 13, 2019<span> | </span><span class="category"><a href="/categories/kafka/">kafka</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer-Group-与-topic-订阅"><span class="toc-number">1.</span> <span class="toc-text">Consumer Group 与 topic 订阅</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Consumer-与-partition"><span class="toc-number">1.1.</span> <span class="toc-text">Consumer 与 partition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Consumer-与Consumer-Group"><span class="toc-number">1.2.</span> <span class="toc-text">Consumer 与Consumer Group</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Coordinator"><span class="toc-number">1.3.</span> <span class="toc-text">Coordinator</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Consumer连接到coordinator"><span class="toc-number">1.3.1.</span> <span class="toc-text">Consumer连接到coordinator</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Consumer-Group-Management"><span class="toc-number">1.4.</span> <span class="toc-text">Consumer Group Management</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer-Fetch-Message"><span class="toc-number">2.</span> <span class="toc-text">Consumer Fetch Message</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#poll-方法"><span class="toc-number">2.1.</span> <span class="toc-text">poll 方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#commit-offset"><span class="toc-number">2.2.</span> <span class="toc-text">commit offset</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Consumer-Configuration"><span class="toc-number">3.</span> <span class="toc-text">Consumer Configuration</span></a></li></ol></div></div><div class="post-content"><h2 id="Consumer-Group-与-topic-订阅"><a href="#Consumer-Group-与-topic-订阅" class="headerlink" title="Consumer Group 与 topic 订阅"></a>Consumer Group 与 topic 订阅</h2><p>每个Consumer 进程都会划归到一个逻辑的Consumer Group中，逻辑的订阅者是Consumer Group。所以一条message可以被多个订阅message 所在的topic的每一个Consumer Group，也就好像是这条message被广播到每个Consumer Group一样。而每个Consumer Group中，类似于一个Queue（JMS中的Queue）的概念差不多，即一条消息只会被Consumer Group中的一个Consumer消费。</p>
<h3 id="Consumer-与-partition"><a href="#Consumer-与-partition" class="headerlink" title="Consumer 与 partition"></a>Consumer 与 partition</h3><p>其实上面所说的订阅关系还不够明确，其实topic中的partition被分配到某个consumer上，也就是某个consumer订阅了某个partition。 再重复一下：consumer订阅的是partition，而不是message。所以在同一时间点上，订阅到同一个partition的consumer必然属于不同的Consumer Group。</p>
<p>在官方网站上，给出了这样一张图：<br>![image](6.kafka Consumer配置/512650-20161111141137717-373606468.png)</p>
<p>一个kafka cluster中的某个topic，有4个partition。有两个consumer group (A and B)订阅了该topic。 Consumer Group A有2个partition：p0、p1，Consumer Group B有4个partition：c3,c4,c5,c6。经过分区分配后，consumer与partition的订阅关系如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Topic 中的4个partition在Consumer Group A中的分配情况如下：</span><br><span class="line">C1 订阅p0,p3</span><br><span class="line">C2 订阅p1,p2</span><br><span class="line">Topic 中的4个partition在Consumer Group B中的分配情况如下：</span><br><span class="line">C3 订阅p0</span><br><span class="line">C4 订阅p3</span><br><span class="line">C5 订阅p1</span><br><span class="line">C6 订阅p2</span><br></pre></td></tr></table></figure>
<p>另外要知道的是，partition分配的工作其实是在consumer leader中完成的。</p>
<h3 id="Consumer-与Consumer-Group"><a href="#Consumer-与Consumer-Group" class="headerlink" title="Consumer 与Consumer Group"></a>Consumer 与Consumer Group</h3><p>Consumer Group与Consumer的关系是动态维护的：<br>当一个Consumer 进程挂掉 或者是卡住时，该consumer所订阅的partition会被重新分配到该group内的其它的consumer上。当一个consumer加入到一个consumer group中时，同样会从其它的consumer中分配出一个或者多个partition 到这个新加入的consumer。</p>
<p>当启动一个Consumer时，会指定它要加入的group，使用的是配置项：group.id。</p>
<p>为了维持Consumer 与 Consumer Group的关系，需要Consumer周期性的发送heartbeat到coordinator（协调者，在早期版本，以zookeeper作为协调者。后期版本则以某个broker作为协调者）。当Consumer由于某种原因不能发Heartbeat到coordinator时，并且时间超过session.timeout.ms时，就会认为该consumer已退出，它所订阅的partition会分配到同一group 内的其它的consumer上。而这个过程，被称为rebalance。</p>
<p>那么现在有这样一个问题：如果一个consumer 进程一直在周期性的发送heartbeat，但是它就是不消费消息，这种状态称为livelock状态。那么在这种状态下，它所订阅的partition不消息是否就一直不能被消费呢？</p>
<h3 id="Coordinator"><a href="#Coordinator" class="headerlink" title="Coordinator"></a>Coordinator</h3><p>Coordinator 协调者，协调consumer、broker。早期版本中Coordinator，使用zookeeper实现，但是这样做，rebalance的负担太重。为了解决scalable的问题，不再使用zookeeper，而是让每个broker来负责一些group的管理，这样consumer就完全不再依赖zookeeper了。</p>
<h4 id="Consumer连接到coordinator"><a href="#Consumer连接到coordinator" class="headerlink" title="Consumer连接到coordinator"></a>Consumer连接到coordinator</h4><p>从Consumer的实现来看，在执行poll或者是join group之前，都要保证已连接到Coordinator。连接到coordinator的过程是：</p>
<ol>
<li>连接到最后一次连接的broker（如果是刚启动的consumer，则要根据配置中的borker）。它会响应一个包含coordinator信息(host, port等)的response。</li>
<li>连接到coordinator。</li>
</ol>
<h3 id="Consumer-Group-Management"><a href="#Consumer-Group-Management" class="headerlink" title="Consumer Group Management"></a>Consumer Group Management</h3><p>Consumer Group 管理中，也是需要coordinator的参与。一个Consumer要join到一个group中，或者一个consumer退出时，都要进行rebalance。进行rebalance的流程是：</p>
<ol>
<li>会给一个coordinator发起Join请求（请求中要包括自己的一些元数据，例如自己感兴趣的topics）</li>
<li>Coordinator 根据这些consumer的join请求，选择出一个leader，并通知给各个consumer。这里的leader是consumer group 内的leader，是由某个consumer担任，不要与partition的leader混淆。</li>
<li>Consumer leader 根据这些consumer的metadata，重新为每个consumer member重新分配partition。分配完毕通过coordinator把最新分配情况同步给每个consumer。</li>
<li>Consumer拿到最新的分配后，继续工作。</li>
</ol>
<h2 id="Consumer-Fetch-Message"><a href="#Consumer-Fetch-Message" class="headerlink" title="Consumer Fetch Message"></a>Consumer Fetch Message</h2><p>在Kafka partition中，每个消息有一个唯一标识，即partition内的offset。每个consumer group中的订阅到某个partition的consumer在从partition中读取数据时，是依次读取的。<br>![image](6.kafka Consumer配置/512650-20161111141305889-2067694137.png)</p>
<p>上图中，Consumer A、B分属于不用的Consumer Group。Consumer B读取到offset =11,Consumer A读取到offset=9 。这个值表示Consumer Group中的某个Consumer 在下次读取该partition时会从哪个offset的 message开始读取，即 Consumer Group A 中的Consumer下次会从offset = 9 的message 读取， Consumer Group B 中的Consumer下次会从offset = 11 的message 读取。<br>这里并没有说是Consumer A 下次会从offset = 9 的message读取，原因是Consumer A可能会退出Group ，然后Group A 进行rebalance，即重新分配分区。</p>
<h3 id="poll-方法"><a href="#poll-方法" class="headerlink" title="poll 方法"></a>poll 方法</h3><p>Consumer读取partition中的数据是通过调用发起一个fetch请求来执行的。而从KafkaConsumer来看，它有一个poll方法。但是这个poll方法只是可能会发起fetch请求。原因是：Consumer每次发起fetch请求时，读取到的数据是有限制的，通过配置项<code>max.partition.fetch.bytes</code>来限制的。而在执行poll方法时，会根据配置项个<code>max.poll.records</code>来限制一次最多pool多少个record。<br>那么就可能出现这样的情况： 在满足<code>max.partition.fetch.bytes</code>限制的情况下，假如fetch到了100个record，放到本地缓存后，由于<code>max.poll.records</code>限制每次只能poll出15个record。那么KafkaConsumer就需要执行7次才能将这一次通过网络发起的fetch请求所fetch到的这100个record消费完毕。其中前6次是每次pool中15个record，最后一次是poll出10个record。<br>在consumer中，还有另外一个配置项：<code>max.poll.interval.ms</code>，它表示最大的poll数据间隔，如果超过这个间隔没有发起pool请求，但heartbeat仍旧在发，就认为该consumer处于 livelock状态。就会将该consumer退出consumer group。所以为了不使Consumer 自己被退出，Consumer 应该不停的发起poll(timeout)操作。而这个动作 KafkaConsumer Client是不会帮我们做的，这就需要自己在程序中不停的调用poll方法了。</p>
<h3 id="commit-offset"><a href="#commit-offset" class="headerlink" title="commit offset"></a>commit offset</h3><p>当一个consumer因某种原因退出Group时，进行重新分配partition后，同一group中的另一个consumer在读取该partition时，怎么能够知道上一个consumer该从哪个offset的message读取呢？也是是如何保证同一个group内的consumer不重复消费消息呢？上面说了一次走网络的fetch请求会拉取到一定量的数据，但是这些数据还没有被消息完毕，Consumer就挂掉了，下一次进行数据fetch时，是否会从上次读到的数据开始读取，而导致Consumer消费的数据丢失吗？<br>为了做到这一点，当使用完poll从本地缓存拉取到数据之后，需要client调用commitSync方法（或者commitAsync方法）去commit 下一次该去读取 哪一个offset的message。<br>而这个commit方法会通过走网络的commit请求将offset在coordinator中保留，这样就能够保证下一次读取（不论进行了rebalance）时，既不会重复消费消息，也不会遗漏消息。<br>对于offset的commit，Kafka Consumer Java Client支持两种模式：由KafkaConsumer自动提交，或者是用户通过调用commitSync、commitAsync方法的方式完成offset的提交。<br>自动提交的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="line">props.put(&quot;group.id&quot;, &quot;test&quot;);</span><br><span class="line">props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);</span><br><span class="line">props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);</span><br><span class="line">props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));</span><br><span class="line">while (true) &#123;</span><br><span class="line">  ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);</span><br><span class="line">    for (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line">      System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;,record.offset(), record.key(), record.value());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>手动提交的例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="line">props.put(&quot;group.id&quot;, &quot;test&quot;);</span><br><span class="line">props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);</span><br><span class="line">props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span><br><span class="line">consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));</span><br><span class="line">final int minBatchSize = 200;</span><br><span class="line">List&lt;ConsumerRecord&lt;String, String&gt;&gt; buffer = new ArrayList&lt;&gt;();</span><br><span class="line">while (true) &#123;</span><br><span class="line">  ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);</span><br><span class="line">  for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">    buffer.add(record);</span><br><span class="line">  &#125;</span><br><span class="line">  if (buffer.size() &gt;= minBatchSize) &#123;</span><br><span class="line">    insertIntoDb(buffer);</span><br><span class="line">    consumer.commitSync();</span><br><span class="line">    buffer.clear();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在手动提交时，需要注意的一点是：要提交的是下一次要读取的offset，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">try &#123;</span><br><span class="line">  while(running) &#123;</span><br><span class="line">    // 取得消息</span><br><span class="line">    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Long.MAX_VALUE);</span><br><span class="line">    // 根据分区来遍历数据：</span><br><span class="line">    for (TopicPartition partition : records.partitions()) &#123;</span><br><span class="line">      List&lt;ConsumerRecord&lt;String, String&gt;&gt; partitionRecords = records.records(partition);</span><br><span class="line">      // 数据处理</span><br><span class="line">      for (ConsumerRecord&lt;String, String&gt; record : partitionRecords) &#123;</span><br><span class="line">        System.out.println(record.offset() + &quot;: &quot; + record.value());</span><br><span class="line">      &#125;</span><br><span class="line">      // 取得当前读取到的最后一条记录的offset</span><br><span class="line">      long lastOffset = partitionRecords.get(partitionRecords.size() - 1).offset();</span><br><span class="line">      // 提交offset，记得要 + 1</span><br><span class="line">      consumer.commitSync(Collections.singletonMap(partition, new OffsetAndMetadata(lastOffset + 1)));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; finally &#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="Consumer-Configuration"><a href="#Consumer-Configuration" class="headerlink" title="Consumer Configuration"></a>Consumer Configuration</h2><p>在kafka 0.9+使用Java Consumer替代了老版本的scala Consumer。新版的配置如下：</p>
<ul>
<li><p>bootstrap.servers<br>在启动consumer时配置的broker地址的。不需要将cluster中所有的broker都配置上，因为启动后会自动的发现cluster所有的broker。</p>
<blockquote>
<p>它配置的格式是：host1:port1;host2:port2…</p>
</blockquote>
</li>
<li><p>key.descrializer、value.descrializer<br>Message record 的key, value的反序列化类。</p>
</li>
<li><p>group.id<br>用于表示该consumer想要加入到哪个group中。默认值是 “”。</p>
</li>
<li><p>heartbeat.interval.ms<br>心跳间隔。心跳是在consumer与coordinator之间进行的。心跳是确定consumer存活，加入或者退出group的有效手段。</p>
<blockquote>
<p>这个值必须设置的小于session.timeout.ms，因为：<br>当Consumer由于某种原因不能发Heartbeat到coordinator时，并且时间超过session.timeout.ms时，就会认为该consumer已退出，它所订阅的partition会分配到同一group 内的其它的consumer上。<br>通常设置的值要低于session.timeout.ms的1/3。<br>默认值是：3000 （3s）</p>
</blockquote>
</li>
<li><p>session.timeout.ms<br>Consumer session 过期时间。这个值必须设置在broker configuration中的group.min.session.timeout.ms 与 group.max.session.timeout.ms之间。<br>其默认值是：10000 （10 s）</p>
</li>
<li><p>enable.auto.commit<br>Consumer 在commit offset时有两种模式：自动提交，手动提交。手动提交在前面已经说过。自动提交：是Kafka Consumer会在后台周期性的去commit。<br>默认值是true。</p>
</li>
<li><p>auto.commit.interval.ms<br>自动提交间隔。范围：[0,Integer.MAX]，默认值是 5000 （5 s）</p>
</li>
<li><p>auto.offset.reset<br>这个配置项，是告诉Kafka Broker在发现kafka在没有初始offset，或者当前的offset是一个不存在的值（如果一个record被删除，就肯定不存在了）时，该如何处理。它有4种处理方式：<br>1） earliest：自动重置到最早的offset。<br>2） latest：看上去重置到最晚的offset。<br>3） none：如果边更早的offset也没有的话，就抛出异常给consumer，告诉consumer在整个consumer group中都没有发现有这样的offset。<br>4） 如果不是上述3种，只抛出异常给consumer。<br>默认值是latest。</p>
</li>
<li><p>connections.max.idle.ms<br>连接空闲超时时间。因为consumer只与broker有连接（coordinator也是一个broker），所以这个配置的是consumer到broker之间的。<br>默认值是：540000 (9 min)</p>
</li>
<li><p>fetch.max.wait.ms<br>Fetch请求发给broker后，在broker中可能会被阻塞的（当topic中records的总size小于fetch.min.bytes时），此时这个fetch请求耗时就会比较长。这个配置就是来配置consumer最多等待response多久。</p>
</li>
<li><p>fetch.min.bytes<br>当consumer向一个broker发起fetch请求时，broker返回的records的大小最小值。如果broker中数据量不够的话会wait，直到数据大小满足这个条件。<br>取值范围是：[0, Integer.Max]，默认值是1。<br>默认值设置为1的目的是：使得consumer的请求能够尽快的返回。</p>
</li>
<li><p>fetch.max.bytes<br>一次fetch请求，从一个broker中取得的records最大大小。如果在从topic中第一个非空的partition取消息时，如果取到的第一个record的大小就超过这个配置时，仍然会读取这个record，也就是说在这片情况下，只会返回这一条record。<br>broker、topic都会对producer发给它的message size做限制。所以在配置这值时，可以参考broker的message.max.bytes 和 topic的max.message.bytes的配置。<br>取值范围是：[0, Integer.Max]，默认值是：52428800 （5 MB）</p>
</li>
<li><p>max.partition.fetch.bytes<br>一次fetch请求，从一个partition中取得的records最大大小。如果在从topic中第一个非空的partition取消息时，如果取到的第一个record的大小就超过这个配置时，仍然会读取这个record，也就是说在这片情况下，只会返回这一条record。<br>broker、topic都会对producer发给它的message size做限制。所以在配置这值时，可以参考broker的message.max.bytes 和 topic的max.message.bytes的配置。</p>
</li>
<li><p>max.poll.interval.ms<br>前面说过要求程序中不间断的调用poll()。如果长时间没有调用poll，且间隔超过这个值时，就会认为这个consumer失败了。</p>
</li>
<li><p>max.poll.records<br>Consumer每次调用poll()时取到的records的最大数。</p>
</li>
<li><p>receive.buffer.bytes<br>Consumer receiver buffer （SO_RCVBUF）的大小。这个值在创建Socket连接时会用到。<br>取值范围是：[-1, Integer.MAX]。默认值是：65536 （64 KB）<br>如果值设置为-1，则会使用操作系统默认的值。</p>
</li>
<li><p>request.timeout.ms<br>请求发起后，并不一定会很快接收到响应信息。这个配置就是来配置请求超时时间的。默认值是：305000 （305 s）</p>
</li>
<li><p>client.id<br>Consumer进程的标识。如果设置一个人为可读的值，跟踪问题会比较方便。</p>
</li>
<li><p>interceptor.classes<br>用户自定义interceptor。</p>
</li>
<li><p>metadata.max.age.ms<br>Metadata数据的刷新间隔。即便没有任何的partition订阅关系变更也行执行。<br>范围是：[0, Integer.MAX]，默认值是：300000 （5 min）</p>
</li>
</ul>
</div><div class="tags"><a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a></div><div class="post-nav"><a class="pre" href="/2019/07/14/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka_2.11-1.1.0%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/">kafka_2.11-1.1.0安装配置</a><a class="next" href="/2019/07/13/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/5.Kafka%E5%A6%82%E4%BD%95%E8%AF%BB%E5%8F%96offset%20topic%E5%86%85%E5%AE%B9/">5.Kafka 如何读取offset topic内容</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://cunmin1718.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Beat/">Beat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ES/">ES</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Elasticsearch/">Elasticsearch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kibana/">Kibana</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LVS/">LVS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Logstash/">Logstash</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nexus/">Nexus</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ansible/">ansible</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/drill/">drill</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ganglia/">ganglia</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/gitLab/">gitLab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/greenplum/">greenplum</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/greenplum/PostgreSQL/">PostgreSQL</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/impala/">impala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/k8s/">k8s</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/maven/">maven</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/oracle/">oracle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/seaweed/">seaweed</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/zookeeper/">zookeeper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size: 15px;">数据仓库</a> <a href="/tags/%E6%9D%82%E8%B0%88/" style="font-size: 15px;">杂谈</a> <a href="/tags/%E5%AE%B9%E5%99%A8/" style="font-size: 15px;">容器</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 15px;">数据库</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/" style="font-size: 15px;">项目开发</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 15px;">运维</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/hadoop%E4%BD%93%E7%B3%BB/" style="font-size: 15px;">hadoop体系</a> <a href="/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/" style="font-size: 15px;">文件存储</a> <a href="/tags/%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E/" style="font-size: 15px;">分析引擎</a> <a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15px;">消息队列</a> <a href="/tags/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/" style="font-size: 15px;">运维监控</a> <a href="/tags/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/" style="font-size: 15px;">日志收集</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Logstash/pipeline%E9%85%8D%E7%BD%AE/">pipeline配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Logstash/Logstash%E4%BB%8B%E7%BB%8D/">Logstash介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/FileBeat6.4%E5%AE%89%E8%A3%85/">FileBeat6.4 安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Logstash/logstash7.4%20%E9%85%8D%E7%BD%AE/">Logstash7.4 配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Kibana/Kibana7.4%E5%AE%89%E8%A3%85/">Kibana7.4安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/ElasticSearch/ES%207.4%E5%AE%89%E8%A3%85/">ES 7.4安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/Maven/15.%20%E6%8F%92%E4%BB%B6maven-enforcer-plugin/">插件maven-enforcer-plugin</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/Maven/14.%20%E6%8F%92%E4%BB%B6build-helper-maven-plugin/">插件build-helper-maven-plugin</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/Inmon%20%20VS%20Kimball/">3. Bill Inmon  VS. Ralph Kimball</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/30/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E8%AE%BE%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/">2. 数据仓库建设中的数据建模方法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">记忆不靠谱.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>