<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="个人笔记"><title>2. 高可靠性存储分析 | 记忆不靠谱</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><meta name="generator" content="Hexo 4.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">2. 高可靠性存储分析</h1><a id="logo" href="/.">记忆不靠谱</a><p class="description">人生很奇妙，过好每一天</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">2. 高可靠性存储分析</h1><div class="post-meta">Jul 7, 2019<span> | </span><span class="category"><a href="/categories/kafka/">kafka</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka文件存储机制"><span class="toc-number">1.</span> <span class="toc-text">Kafka文件存储机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#复制原理和同步方式"><span class="toc-number">2.</span> <span class="toc-text">复制原理和同步方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ISR"><span class="toc-number">3.</span> <span class="toc-text">ISR</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据可靠性和持久性保证"><span class="toc-number">4.</span> <span class="toc-text">数据可靠性和持久性保证</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#request-required-acks-1"><span class="toc-number">4.1.</span> <span class="toc-text">request.required.acks=1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#request-required-acks-1-1"><span class="toc-number">4.2.</span> <span class="toc-text">request.required.acks=-1</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#关于HW的进一步探讨"><span class="toc-number">5.</span> <span class="toc-text">关于HW的进一步探讨</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Leader选举"><span class="toc-number">6.</span> <span class="toc-text">Leader选举</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka的发送模式"><span class="toc-number">7.</span> <span class="toc-text">Kafka的发送模式</span></a></li></ol></div></div><div class="post-content"><p>Kafka的高可靠性的保障来源于其健壮的副本（replication）策略。通过调节其副本相关参数，可以使得Kafka在性能和可靠性之间运转的游刃有余。Kafka从0.8.x版本开始提供partition级别的复制,replication的数量可以在<code>$KAFKA_HOME/config/server.properties</code>中配置（default.replication.factor）。</p>
<p>这里先从Kafka文件存储机制入手，从最底层了解Kafka的存储细节，进而对其的存储有个微观的认知。之后通过Kafka复制原理和同步方式来阐述宏观层面的概念。最后从ISR，HW，leader选举以及数据可靠性和持久性保证等等各个维度来丰富对Kafka相关知识点的认知。</p>
<a id="more"></a>

<h2 id="Kafka文件存储机制"><a href="#Kafka文件存储机制" class="headerlink" title="Kafka文件存储机制"></a>Kafka文件存储机制</h2><p>Kafka中消息是以topic进行分类的，生产者通过topic向Kafka broker发送消息，消费者通过topic读取数据。然而topic在物理层面又能以partition为分组，一个topic可以分成若干个partition，那么topic以及partition又是怎么存储的呢？partition还可以细分为segment，一个partition物理上由多个segment组成，那么这些segment又是什么呢？下面我们来一一揭晓。</p>
<p>为了便于说明问题，假设这里只有一个Kafka集群，且这个集群只有一个Kafka broker，即只有一台物理机。在这个Kafka broker中配置（$KAFKA_HOME/config/server.properties中）log.dirs=/tmp/kafka-logs，以此来设置Kafka消息文件存储目录，与此同时创建一个topic：topic_zzh_test，partition的数量为4（$KAFKA_HOME/bin/kafka-topics.sh –create –zookeeper localhost:2181 –partitions 4 –topic topic_zzh_test –replication-factor 1）。那么我们此时可以在/tmp/kafka-logs目录中可以看到生成了4个目录:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">drwxr-xr-x 2 root root 4096 Apr 10 16:10 topic_zzh_test-0</span><br><span class="line">drwxr-xr-x 2 root root 4096 Apr 10 16:10 topic_zzh_test-1</span><br><span class="line">drwxr-xr-x 2 root root 4096 Apr 10 16:10 topic_zzh_test-2</span><br><span class="line">drwxr-xr-x 2 root root 4096 Apr 10 16:10 topic_zzh_test-3</span><br></pre></td></tr></table></figure>
<p>在Kafka文件存储中，同一个topic下有多个不同的partition，每个partiton为一个目录，partition的名称规则为：topic名称+有序序号，第一个序号从0开始计，最大的序号为partition数量减1，partition是实际物理上的概念，而topic是逻辑上的概念。</p>
<p>上面提到partition还可以细分为segment，这个segment又是什么？如果就以partition为最小存储单位，我们可以想象当Kafka producer不断发送消息，必然会引起partition文件的无限扩张，这样对于消息文件的维护以及已经被消费的消息的清理带来严重的影响，所以这里以segment为单位又将partition细分。每个partition(目录)相当于一个巨型文件被平均分配到多个大小相等的segment(段)数据文件中（每个segment 文件中消息数量不一定相等）这种特性也方便old segment的删除，即方便已被消费的消息的清理，提高磁盘的利用率。每个partition只需要支持顺序读写就行，segment的文件生命周期由服务端配置参数（log.segment.bytes，log.roll.{ms,hours}等若干参数）决定。</p>
<p>segment文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为segment索引文件和数据文件。这两个文件的命令规则为：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值，数值大小为64位，20位数字字符长度，没有数字用0填充，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br></pre></td></tr></table></figure>
<p>以上面的segment文件为例，展示出segment：00000000000000170410的“.index”文件和“.log”文件的对应的关系，如下图：<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170506094723439.png" alt="image"></p>
<p>如上图，“.index”索引文件存储大量的元数据，“.log”数据文件存储大量的消息，索引文件中的元数据指向对应数据文件中message的物理偏移地址。其中以“.index”索引文件中的元数据[3, 348]为例，在“.log”数据文件表示第3个消息，即在全局partition中表示170410+3=170413个消息，该消息的物理偏移地址为348。</p>
<p>那么如何从partition中通过offset查找message呢？<br>以上图为例，读取offset=170418的消息，首先查找segment文件，其中00000000000000000000.index为最开始的文件，第二个文件为00000000000000170410.index（起始偏移为170410+1=170411），而第三个文件为00000000000000239430.index（起始偏移为239430+1=239431），所以这个offset=170418就落到了第二个文件之中。其他后续文件可以依次类推，以其实偏移量命名并排列这些文件，然后根据二分查找法就可以快速定位到具体文件位置。其次根据00000000000000170410.index文件中的[8,1325]定位到00000000000000170410.log文件中的1325的位置进行读取。</p>
<blockquote>
<p>要是读取offset=170418的消息，从00000000000000170410.log文件中的1325的位置进行读取，那么怎么知道何时读完本条消息，否则就读到下一条消息的内容了？<br>这个就需要联系到消息的物理结构了，消息都具有固定的物理结构，包括：offset（8 Bytes）、消息体的大小（4 Bytes）、crc32（4 Bytes）、magic（1 Byte）、attributes（1 Byte）、key length（4 Bytes）、key（K Bytes）、payload(N Bytes)等等字段，可以确定一条消息的大小，即读取到哪里截止。</p>
</blockquote>
<h2 id="复制原理和同步方式"><a href="#复制原理和同步方式" class="headerlink" title="复制原理和同步方式"></a>复制原理和同步方式</h2><p>Kafka中topic的每个partition有一个预写式的日志文件，虽然partition可以继续细分为若干个segment文件，但是对于上层应用来说可以将partition看成最小的存储单元（一个有多个segment文件拼接的“巨型”文件），每个partition都由一些列有序的、不可变的消息组成，这些消息被连续的追加到partition中。<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170506094740547.png" alt="image"></p>
<p>上图中有两个新名词：HW和LEO。这里先介绍下LEO，LogEndOffset的缩写，表示每个partition的log最后一条Message的位置。HW是HighWatermark的缩写，是指consumer能够看到的此partition的位置，这个涉及到多副本的概念，这里先提及一下，下节再详表。</p>
<p>言归正传，为了提高消息的可靠性，Kafka每个topic的partition有N个副本（replicas），其中N(大于等于1)是topic的复制因子（replica fator）的个数。Kafka通过多副本机制实现故障自动转移，当Kafka集群中一个broker失效情况下仍然保证服务可用。在Kafka中发生复制时确保partition的日志能有序地写到其他节点上，N个replicas中，其中一个replica为leader，其他都为follower, leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。<br>如下图所示，Kafka集群中有4个broker, 某topic有3个partition,且复制因子即副本个数也为3：<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170506094800641.png" alt="image"></p>
<p>Kafka提供了数据复制算法保证，如果leader发生故障或挂掉，一个新leader被选举并被接受客户端的消息成功写入。Kafka确保从同步副本列表中选举一个副本为leader，或者说follower追赶leader数据。leader负责维护和跟踪ISR(In-Sync Replicas的缩写，表示副本同步队列，具体可参考下节)中所有follower滞后的状态。当producer发送一条消息到broker后，leader写入消息并复制到所有follower。消息提交之后才被成功复制到所有的同步副本。消息复制延迟受最慢的follower限制，重要的是快速检测慢副本，如果follower“落后”太多或者失效，leader将会把它从ISR中删除。</p>
<h2 id="ISR"><a href="#ISR" class="headerlink" title="ISR"></a>ISR</h2><p>上节我们涉及到ISR (In-Sync Replicas)，这个是指副本同步队列。副本数对Kafka的吞吐率是有一定的影响，但极大的增强了可用性。默认情况下Kafka的replica数量为1，即每个partition都有一个唯一的leader，为了确保消息的可靠性，通常应用中将其值(由broker的参数offsets.topic.replication.factor指定)大小设置为大于1，比如3。 所有的副本（replicas）统称为Assigned Replicas，即AR。ISR是AR中的一个子集，由leader维护ISR列表，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。</p>
<p>Kafka 0.9.0.0版本后移除了replica.lag.max.messages参数，只保留了replica.lag.time.max.ms作为ISR中副本管理的参数。为什么这样做呢？replica.lag.max.messages表示当前某个副本落后leader的消息数量超过了这个参数的值，那么leader就会把follower从ISR中删除。假设设置replica.lag.max.messages=4，那么如果producer一次传送至broker的消息数量都小于4条时，因为在leader接受到producer发送的消息之后而follower副本开始拉取这些消息之前，follower落后leader的消息数不会超过4条消息，故此没有follower移出ISR，所以这时候replica.lag.max.message的设置似乎是合理的。但是producer发起瞬时高峰流量，producer一次发送的消息超过4条时，也就是超过replica.lag.max.messages，此时follower都会被认为是与leader副本不同步了，从而被踢出了ISR。但实际上这些follower都是存活状态的且没有性能问题。那么在之后追上leader,并被重新加入了ISR。于是就会出现它们不断地剔出ISR然后重新回归ISR，这无疑增加了无谓的性能损耗。而且这个参数是broker全局的。设置太大了，影响真正“落后”follower的移除；设置的太小了，导致follower的频繁进出。无法给定一个合适的replica.lag.max.messages的值，故此，新版本的Kafka移除了这个参数。</p>
<blockquote>
<p>注：ISR中包括：leader和follower。</p>
</blockquote>
<p>上面一节还涉及到一个概念，即HW。HW俗称高水位，HighWatermark的缩写，取一个partition对应的ISR中最小的LEO作为HW，consumer最多只能消费到HW所在的位置。另外每个replica都有HW,leader和follower各自负责更新自己的HW的状态。对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。对于来自内部broker的读取请求，没有HW的限制。</p>
<p>下图详细的说明了当producer生产消息至broker后，ISR以及HW和LEO的流转过程：<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170506094838798.png" alt="image"></p>
<p>由此可见，Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower都复制完，这条消息才会被commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下如果follower都还没有复制完，落后于leader时，突然leader宕机，则会丢失数据。而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。</p>
<p>Kafka的ISR的管理最终都会反馈到Zookeeper节点上。具体位置为：/brokers/topics/[topic]/partitions/[partition]/state。目前有两个地方会对这个Zookeeper的节点进行维护：</p>
<ol>
<li>Controller来维护：Kafka集群中的其中一个Broker会被选举为Controller，主要负责Partition管理和副本状态管理，也会执行类似于重分配partition之类的管理任务。在符合某些特定条件下，Controller下的LeaderSelector会选举新的leader，ISR和新的leader_epoch及controller_epoch写入Zookeeper的相关节点中。同时发起LeaderAndIsrRequest通知所有的replicas。</li>
<li>leader来维护：leader有单独的线程定期检测ISR中follower是否脱离ISR, 如果发现ISR变化，则会将新的ISR的信息返回到Zookeeper的相关节点中。</li>
</ol>
<h2 id="数据可靠性和持久性保证"><a href="#数据可靠性和持久性保证" class="headerlink" title="数据可靠性和持久性保证"></a>数据可靠性和持久性保证</h2><p>当producer向leader发送数据时，可以通过request.required.acks参数来设置数据可靠性的级别：</p>
<ul>
<li>1（默认）：这意味着producer在ISR中的leader已成功收到数据并得到确认。如果leader宕机了，则会丢失数据。</li>
<li>0：这意味着producer无需等待来自broker的确认而继续发送下一批消息。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li>
<li>-1：producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。但是这样也不能保证数据不丢失，比如当ISR中只有leader时（前面ISR那一节讲到，ISR中的成员由于某些情况会增加也会减少，最少就只剩一个leader），这样就变成了acks=1的情况。</li>
</ul>
<p>如果要提高数据的可靠性，在设置request.required.acks=-1的同时，也要min.insync.replicas这个参数(可以在broker或者topic层面进行设置)的配合，这样才能发挥最大的功效。min.insync.replicas这个参数设定ISR中的最小副本数是多少，默认值为1，当且仅当request.required.acks参数设置为-1时，此参数才生效。如果ISR中的副本数少于min.insync.replicas配置的数量时，客户端会返回异常：<br>org.apache.kafka.common.errors.NotEnoughReplicasExceptoin: Messages are rejected since there are fewer in-sync replicas than required。</p>
<p>接下来对acks=1和-1的两种情况进行详细分析：</p>
<h3 id="request-required-acks-1"><a href="#request-required-acks-1" class="headerlink" title="request.required.acks=1"></a>request.required.acks=1</h3><p>producer发送数据到leader，leader写本地日志成功，返回客户端成功；此时ISR中的副本还没有来得及拉取该消息，leader就宕机了，那么此次发送的消息就会丢失。</p>
<h3 id="request-required-acks-1-1"><a href="#request-required-acks-1-1" class="headerlink" title="request.required.acks=-1"></a>request.required.acks=-1</h3><p>同步（Kafka默认为同步，即producer.type=sync）的发送模式，replication.factor&gt;=2且min.insync.replicas&gt;=2的情况下，不会丢失数据。</p>
<p>有两种典型情况。acks=-1的情况下（如无特殊说明，以下acks都表示为参数request.required.acks），数据发送到leader, ISR的follower全部完成数据同步后，leader此时挂掉，那么会选举出新的leader，数据不会丢失。<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170612101036994.png" alt="image"></p>
<p>acks=-1的情况下，数据发送到leader后 ，部分ISR的副本同步，leader此时挂掉。比如follower1和follower2都有可能变成新的leader, producer端会得到返回异常，producer端会重新发送数据，数据可能会重复。<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170612101817963.png" alt="image"></p>
<p>当然上图中如果在leader crash的时候，follower2还没有同步到任何数据，而且follower2被选举为新的leader的话，这样消息就不会重复。</p>
<h2 id="关于HW的进一步探讨"><a href="#关于HW的进一步探讨" class="headerlink" title="关于HW的进一步探讨"></a>关于HW的进一步探讨</h2><p>考虑上图（即acks=-1,部分ISR副本同步）中的另一种情况，如果在Leader挂掉的时候，follower1同步了消息4,5，follower2同步了消息4，与此同时follower2被选举为leader，那么此时follower1中的多出的消息5该做如何处理呢？</p>
<p>这里就需要HW的协同配合了。如前所述，一个partition中的ISR列表中，leader的HW是所有ISR列表里副本中最小的那个的LEO。类似于木桶原理，水位取决于最低那块短板。<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170506094954568.png" alt="image"></p>
<p>如上图，某个topic的某partition有三个副本，分别为A、B、C。A作为leader肯定是LEO最高，B紧随其后，C机器由于配置比较低，网络比较差，故而同步最慢。这个时候A机器宕机，这时候如果B成为leader，假如没有HW，在A重新恢复之后会做同步(makeFollower)操作，在宕机时log文件之后直接做追加操作，而假如B的LEO已经达到了A的LEO，会产生数据不一致的情况，所以使用HW来避免这种情况。<br>A在做同步操作的时候，先将log文件截断到之前自己的HW的位置，即3，之后再从B中拉取消息进行同步。</p>
<p>如果失败的follower恢复过来，它首先将自己的log文件截断到上次checkpointed时刻的HW的位置，之后再从leader中同步消息。leader挂掉会重新选举，新的leader会发送“指令”让其余的follower截断至自身的HW的位置然后再拉取新的消息。</p>
<blockquote>
<p>当ISR中的个副本的LEO不一致时，如果此时leader挂掉，选举新的leader时并不是按照LEO的高低进行选举，而是按照ISR中的顺序选举。</p>
</blockquote>
<h2 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h2><p>一条消息只有被ISR中的所有follower都从leader复制过去才会被认为已提交。这样就避免了部分数据被写进了leader，还没来得及被任何follower复制就宕机了，而造成数据丢失。而对于producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks来设置。这种机制确保了只要ISR中有一个或者以上的follower，一条被commit的消息就不会丢失。</p>
<p>有一个很重要的问题是当leader宕机了，怎样在follower中选举出新的leader，因为follower可能落后很多或者直接crash了，所以必须确保选择“最新”的follower作为新的leader。一个基本的原则就是，如果leader不在了，新的leader必须拥有原来的leader commit的所有消息。这就需要做一个折中，如果leader在一个消息被commit前等待更多的follower确认，那么在它挂掉之后就有更多的follower可以成为新的leader，但这也会造成吞吐率的下降。</p>
<p>一种非常常用的选举leader的方式是“少数服从多数”，Kafka并不是采用这种方式。这种模式下，如果我们有2f+1个副本，那么在commit之前必须保证有f+1个replica复制完消息，同时为了保证能正确选举出新的leader，失败的副本数不能超过f个。这种方式有个很大的优势，系统的延迟取决于最快的几台机器，也就是说比如副本数为3，那么延迟就取决于最快的那个follower而不是最慢的那个。“少数服从多数”的方式也有一些劣势，为了保证leader选举的正常进行，它所能容忍的失败的follower数比较少，如果要容忍1个follower挂掉，那么至少要3个以上的副本，如果要容忍2个follower挂掉，必须要有5个以上的副本。也就是说，在生产环境下为了保证较高的容错率，必须要有大量的副本，而大量的副本又会在大数据量下导致性能的急剧下降。这种算法更多用在Zookeeper这种共享集群配置的系统中而很少在需要大量数据的系统中使用的原因。HDFS的HA功能也是基于“少数服从多数”的方式，但是其数据存储并不是采用这样的方式。</p>
<p>实际上，leader选举的算法非常多，比如Zookeeper的Zab、Raft以及Viewstamped Replication。而Kafka所使用的leader选举算法更像是微软的PacificA算法。</p>
<p>Kafka在Zookeeper中为每一个partition动态的维护了一个ISR，这个ISR里的所有replica都跟上了leader，只有ISR里的成员才能有被选为leader的可能（unclean.leader.election.enable=false）。在这种模式下，对于f+1个副本，一个Kafka topic能在保证不丢失已经commit消息的前提下容忍f个副本的失败，在大多数使用场景下，这种模式是十分有利的。事实上，为了容忍f个副本的失败，“少数服从多数”的方式和ISR在commit前需要等待的副本的数量是一样的，但是ISR需要的总的副本的个数几乎是“少数服从多数”的方式的一半。</p>
<p>上文提到，在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某一个partition的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ol>
<li>等待ISR中任意一个replica“活”过来，并且选它作为leader</li>
<li>选择第一个“活”过来的replica（并不一定是在ISR中）作为leader</li>
</ol>
<p>这就需要在可用性和一致性当中作出一个简单的抉择。如果一定要等待ISR中的replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中所有的replica都无法“活”过来了，或者数据丢失了，这个partition将永远不可用。选择第一个“活”过来的replica作为leader,而这个replica不是ISR中的replica,那即使它并不保障已经包含了所有已commit的消息，它也会成为leader而作为consumer的数据源。默认情况下，Kafka采用第二种策略，即unclean.leader.election.enable=true，也可以将此参数设置为false来启用第一种策略。</p>
<p>unclean.leader.election.enable这个参数对于leader的选举、系统的可用性以及数据的可靠性都有至关重要的影响。下面我们来分析下几种典型的场景。<br><img src="/2019/07/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/2.%E9%AB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%AD%98%E5%82%A8%E5%88%86%E6%9E%90/20170506095017533.png" alt="image"></p>
<p>如果上图所示，假设某个partition中的副本数为3，replica-0, replica-1, replica-2分别存放在broker0, broker1和broker2中。AR=(0,1,2)，ISR=(0,1)。<br>设置request.required.acks=-1, min.insync.replicas=2，unclean.leader.election.enable=false。这里将broker0中的副本也称之为broker0起初broker0为leader，broker1为follower。</p>
<ul>
<li><p>当ISR中的replica-0出现crash的情况时，broker1选举为新的leader[ISR=(1)]，因为受min.insync.replicas=2影响，write不能服务，但是read能继续正常服务。此种情况恢复方案：</p>
<ol>
<li>尝试恢复(重启)replica-0，如果能起来，系统正常；</li>
<li>如果replica-0不能恢复，需要将min.insync.replicas设置为1，恢复write功能。</li>
</ol>
</li>
<li><p>当ISR中的replica-0出现crash，紧接着replica-1也出现了crash, 此时[ISR=(1),leader=-1],不能对外提供服务，此种情况恢复方案：</p>
<ol>
<li>尝试恢复replica-0和replica-1，如果都能起来，则系统恢复正常；</li>
<li>如果replica-0起来，而replica-1不能起来，这时候仍然不能选出leader，因为当设置unclean.leader.election.enable=false时，leader只能从ISR中选举，当ISR中所有副本都失效之后，需要ISR中最后失效的那个副本能恢复之后才能选举leader, 即replica-0先失效，replica-1后失效，需要replica-1恢复后才能选举leader。保守的方案建议把unclean.leader.election.enable设置为true,但是这样会有丢失数据的情况发生，这样可以恢复read服务。同样需要将min.insync.replicas设置为1，恢复write功能；</li>
<li>replica-1恢复，replica-0不能恢复，这个情况上面遇到过，read服务可用，需要将min.insync.replicas设置为1，恢复write功能；</li>
<li>replica-0和replica-1都不能恢复，这种情况可以参考情形2.</li>
</ol>
</li>
<li><p>当ISR中的replica-0, replica-1同时宕机,此时[ISR=(0,1)],不能对外提供服务，此种情况恢复方案：尝试恢复replica-0和replica-1，当其中任意一个副本恢复正常时，对外可以提供read服务。直到2个副本恢复正常，write功能才能恢复，或者将将min.insync.replicas设置为1。</p>
</li>
</ul>
<h2 id="Kafka的发送模式"><a href="#Kafka的发送模式" class="headerlink" title="Kafka的发送模式"></a>Kafka的发送模式</h2><p>Kafka的发送模式由producer端的配置参数producer.type来设置，这个参数指定了在后台线程中消息的发送方式是同步的还是异步的，默认是同步的方式，即producer.type=sync。如果设置成异步的模式，即producer.type=async，可以是producer以batch的形式push数据，这样会极大的提高broker的性能，但是这样会增加丢失数据的风险。如果需要确保消息的可靠性，必须要将producer.type设置为sync。<br>对于异步模式，还有4个配套的参数，如下：</p>
<table>
<thead>
<tr>
<th>Property</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td>queue.buffering.max.ms</td>
<td align="left">默认值：5000。启用异步模式时，producer缓存消息的时间。比如我们设置成1000时，它会缓存1s的数据再一次发送出去，这样可以极大的增加broker吞吐量，但也会造成时效性的降低。</td>
</tr>
<tr>
<td>queue.buffering.max.messages</td>
<td align="left">默认值：10000。启用异步模式时，producer缓存队列里最大缓存的消息数量，如果超过这个值，producer就会阻塞或者丢掉消息。</td>
</tr>
<tr>
<td>queue.enqueue.timeout.ms</td>
<td align="left">默认值：-1。当达到上面参数时producer会阻塞等待的时间。如果设置为0，buffer队列满时producer不会阻塞，消息直接被丢掉；若设置为-1，producer会被阻塞，不会丢消息。</td>
</tr>
<tr>
<td>batch.num.messages</td>
<td align="left">默认值：200。启用异步模式时，一个batch缓存的消息数量。达到这个数值时，producer才会发送消息。（每次批量发送的数量）</td>
</tr>
</tbody></table>
<blockquote>
<p>以batch的方式推送数据可以极大的提高处理效率，kafka producer可以将消息在内存中累计到一定数量后作为一个batch发送请求。batch的数量大小可以通过producer的参数（batch.num.messages）控制。通过增加batch的大小，可以减少网络请求和磁盘IO的次数，当然具体参数设置需要在效率和时效性方面做一个权衡。在比较新的版本中还有batch.size这个参数。</p>
</blockquote>
</div><div class="tags"><a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a></div><div class="post-nav"><a class="pre" href="/2019/07/08/%E8%BF%90%E7%BB%B4/ansible/Ansible%20%E5%AE%89%E8%A3%85/">1. Ansible 安装</a><a class="next" href="/2019/07/07/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/Maven/Maven%E7%9A%84pom%E6%A0%87%E7%AD%BE/">Maven的pom标签</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://cunmin1718.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Beat/">Beat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ES/">ES</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Elasticsearch/">Elasticsearch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kibana/">Kibana</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LVS/">LVS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Logstash/">Logstash</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nexus/">Nexus</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ansible/">ansible</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/drill/">drill</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ganglia/">ganglia</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/gitLab/">gitLab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/greenplum/">greenplum</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/greenplum/PostgreSQL/">PostgreSQL</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/impala/">impala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/k8s/">k8s</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/maven/">maven</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/oracle/">oracle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/seaweed/">seaweed</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/zookeeper/">zookeeper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size: 15px;">数据仓库</a> <a href="/tags/%E6%9D%82%E8%B0%88/" style="font-size: 15px;">杂谈</a> <a href="/tags/%E5%AE%B9%E5%99%A8/" style="font-size: 15px;">容器</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 15px;">数据库</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/" style="font-size: 15px;">项目开发</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 15px;">运维</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/hadoop%E4%BD%93%E7%B3%BB/" style="font-size: 15px;">hadoop体系</a> <a href="/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/" style="font-size: 15px;">文件存储</a> <a href="/tags/%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E/" style="font-size: 15px;">分析引擎</a> <a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15px;">消息队列</a> <a href="/tags/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/" style="font-size: 15px;">运维监控</a> <a href="/tags/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/" style="font-size: 15px;">日志收集</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Logstash/pipeline%E9%85%8D%E7%BD%AE/">pipeline配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Logstash/Logstash%E4%BB%8B%E7%BB%8D/">Logstash介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/FileBeat6.4%E5%AE%89%E8%A3%85/">FileBeat6.4 安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Logstash/logstash7.4%20%E9%85%8D%E7%BD%AE/">Logstash7.4 配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/03/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/Kibana/Kibana7.4%E5%AE%89%E8%A3%85/">Kibana7.4安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/ElasticSearch/ES%207.4%E5%AE%89%E8%A3%85/">ES 7.4安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/Maven/15.%20%E6%8F%92%E4%BB%B6maven-enforcer-plugin/">插件maven-enforcer-plugin</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/Maven/14.%20%E6%8F%92%E4%BB%B6build-helper-maven-plugin/">插件build-helper-maven-plugin</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/02/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/Inmon%20%20VS%20Kimball/">3. Bill Inmon  VS. Ralph Kimball</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/30/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E8%AE%BE%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95/">2. 数据仓库建设中的数据建模方法</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">记忆不靠谱.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>