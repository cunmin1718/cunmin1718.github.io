<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="个人笔记"><title>hadoop2.x架构 | 记忆不靠谱</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><meta name="generator" content="Hexo 4.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">hadoop2.x架构</h1><a id="logo" href="/.">记忆不靠谱</a><p class="description">人生很奇妙，过好每一天</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">hadoop2.x架构</h1><div class="post-meta">Jul 15, 2019<span> | </span><span class="category"><a href="/categories/hadoop/">hadoop</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop-系统架构"><span class="toc-number">1.</span> <span class="toc-text">Hadoop 系统架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-2-x元数据"><span class="toc-number">1.1.</span> <span class="toc-text">Hadoop 2.x元数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QJM原理"><span class="toc-number">2.</span> <span class="toc-text">QJM原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#QJM背景"><span class="toc-number">2.1.</span> <span class="toc-text">QJM背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#QJM原理-1"><span class="toc-number">2.2.</span> <span class="toc-text">QJM原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#QJM介绍"><span class="toc-number">2.2.1.</span> <span class="toc-text">QJM介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#QJM-写过程分析"><span class="toc-number">2.2.2.</span> <span class="toc-text">QJM 写过程分析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#隔离双写："><span class="toc-number">2.2.2.1.</span> <span class="toc-text">隔离双写：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#恢复in-process日志"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">恢复in-process日志</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#日志同步"><span class="toc-number">2.2.2.3.</span> <span class="toc-text">日志同步</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#QJM读过程分析"><span class="toc-number">2.2.3.</span> <span class="toc-text">QJM读过程分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主备切换机制"><span class="toc-number">3.</span> <span class="toc-text">主备切换机制</span></a></li></ol></div></div><div class="post-content"><h2 id="Hadoop-系统架构"><a href="#Hadoop-系统架构" class="headerlink" title="Hadoop 系统架构"></a>Hadoop 系统架构</h2><p>2.x版本中，HDFS架构解决了单点故障问题，即引入双NameNode架构，同时借助共享存储系统来进行元数据的同步，共享存储系统类型一般有几类，如：Shared NAS+NFS、BookKeeper、BackupNode 和 Quorum Journal Manager(QJM)，这里用的是QJM作为共享存储组件，通过搭建奇数结点的JournalNode实现主备NameNode元数据操作信息同步。Hadoop的元数据包括哪些信息呢，下面介绍下关于元数据方面的知识。<br><img src="/2019/07/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop%E4%BD%93%E7%B3%BB/hadoop/hadoop2.x%E6%9E%B6%E6%9E%84/1508123304408_8679_1508123329295.png" alt="image"></p>
<h3 id="Hadoop-2-x元数据"><a href="#Hadoop-2-x元数据" class="headerlink" title="Hadoop 2.x元数据"></a>Hadoop 2.x元数据</h3><p>Hadoop的元数据主要作用是维护HDFS文件系统中文件和目录相关信息。元数据的存储形式主要有3类：内存镜像、磁盘镜像(FSImage)、日志(EditLog)。在Namenode启动时，会加载磁盘镜像到内存中以进行元数据的管理，存储在NameNode内存；磁盘镜像是某一时刻HDFS的元数据信息的快照，包含所有相关Datanode节点文件块映射关系和命名空间(Namespace)信息，存储在NameNode本地文件系统；日志文件记录client发起的每一次操作信息，即保存所有对文件系统的修改操作，用于定期和磁盘镜像合并成最新镜像，保证NameNode元数据信息的完整，存储在NameNode本地和共享存储系统(QJM)中。</p>
<p>如下所示为NameNode本地的EditLog和FSImage文件格式，EditLog文件有两种状态： inprocess和finalized, inprocess表示正在写的日志文件，文件名形式:<code>editsinprocess[start-txid]</code>，finalized表示已经写完的日志文件,文件名形式：<code>edits[start-txid][end-txid]</code>； FSImage文件也有两种状态, <code>finalized</code>和<code>checkpoint</code>， finalized表示已经持久化磁盘的文件，文件名形式: <code>fsimage_[end-txid]</code>, checkpoint表示合并中的fsimage, 2.x版本checkpoint过程在Standby Namenode(SNN)上进行，SNN会定期将本地FSImage和从QJM上拉回的ANN的EditLog进行合并，合并完后再通过RPC传回ANN。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">data/hbase/runtime/namespace</span><br><span class="line">├── current</span><br><span class="line">│ ├── VERSION</span><br><span class="line">│ ├── edits_0000000003619794209-0000000003619813881</span><br><span class="line">│ ├── edits_0000000003619813882-0000000003619831665</span><br><span class="line">│ ├── edits_0000000003619831666-0000000003619852153</span><br><span class="line">│ ├── edits_0000000003619852154-0000000003619871027</span><br><span class="line">│ ├── edits_0000000003619871028-0000000003619880765</span><br><span class="line">│ ├── edits_0000000003619880766-0000000003620060869</span><br><span class="line">│ ├── edits_inprogress_0000000003620060870</span><br><span class="line">│ ├── fsimage_0000000003618370058</span><br><span class="line">│ ├── fsimage_0000000003618370058.md5</span><br><span class="line">│ ├── fsimage_0000000003620060869</span><br><span class="line">│ ├── fsimage_0000000003620060869.md5</span><br><span class="line">│ └── seen_txid</span><br><span class="line">└── in_use.lock</span><br></pre></td></tr></table></figure>
<p>上面所示的还有一个很重要的文件就是seen_txid,保存的是一个事务ID，这个事务ID是EditLog最新的一个结束事务id，当NameNode重启时，会顺序遍历从edits_0000000000000000001到seen_txid所记录的txid所在的日志文件，进行元数据恢复，如果该文件丢失或记录的事务ID有问题，会造成数据块信息的丢失。</p>
<p>HA其本质上就是要保证主备NN元数据是保持一致的，即保证fsimage和editlog在备NN上也是完整的。元数据的同步很大程度取决于EditLog的同步，而这步骤的关键就是共享文件系统，下面开始介绍一下关于QJM共享存储机制。</p>
<h2 id="QJM原理"><a href="#QJM原理" class="headerlink" title="QJM原理"></a>QJM原理</h2><h3 id="QJM背景"><a href="#QJM背景" class="headerlink" title="QJM背景"></a>QJM背景</h3><p>在QJM出现之前，为保障集群的HA，设计的是一种基于NAS的共享存储机制，即主备NameNode间通过NAS进行元数据的同步。该方案有什么缺点呢，主要有以下几点：</p>
<ul>
<li>定制化硬件设备：必须是支持NAS的设备才能满足需求</li>
<li>复杂化部署过程：在部署好NameNode后，还必须额外配置NFS挂载、定制隔离脚本，部署易出错</li>
<li>简陋化NFS客户端：Bug多，部署配置易出错，导致HA不可用</li>
</ul>
<p>所以对于替代方案而言，也必须解决NAS相关缺陷才能让HA更好服务。即设备无须定制化，普通设备即可配置HA，部署简单，相关配置集成到系统本身，无需自己定制，同时元数据的同步也必须保证完全HA，不会因client问题而同步失败。</p>
<h3 id="QJM原理-1"><a href="#QJM原理-1" class="headerlink" title="QJM原理"></a>QJM原理</h3><h4 id="QJM介绍"><a href="#QJM介绍" class="headerlink" title="QJM介绍"></a>QJM介绍</h4><p>QJM全称是Quorum Journal Manager, 由JournalNode（JN）组成，一般是奇数点结点组成。每个JournalNode对外有一个简易的RPC接口，以供NameNode读写EditLog到JN本地磁盘。当写EditLog时，NameNode会同时向所有JournalNode并行写文件，只要有N/2+1结点写成功则认为此次写操作成功，遵循Paxos协议。其内部实现框架如下：<br><img src="/2019/07/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop%E4%BD%93%E7%B3%BB/hadoop/hadoop2.x%E6%9E%B6%E6%9E%84/1508123397521_3709_1508123422520.png" alt="image"></p>
<p>从图中可看出，主要是涉及EditLog的不同管理对象和输出流对象，每种对象发挥着各自不同作用：</p>
<ul>
<li>FSEditLog：所有EditLog操作的入口</li>
<li>JournalSet: 集成本地磁盘和JournalNode集群上EditLog的相关操作</li>
<li>FileJournalManager: 实现本地磁盘上 EditLog 操作</li>
<li>QuorumJournalManager: 实现JournalNode 集群EditLog操作</li>
<li>AsyncLoggerSet: 实现JournalNode 集群 EditLog 的写操作集合</li>
<li>AsyncLogger：发起RPC请求到JN，执行具体的日志同步功能</li>
<li>JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。</li>
<li>JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。</li>
</ul>
<p>下面具体分析下QJM的读写过程。</p>
<h4 id="QJM-写过程分析"><a href="#QJM-写过程分析" class="headerlink" title="QJM 写过程分析"></a>QJM 写过程分析</h4><p>上面提到EditLog，NameNode会把EditLog同时写到本地和JournalNode。写本地由配置中参数dfs.namenode.name.dir控制，写JN由参数dfs.namenode.shared.edits.dir控制，在写EditLog时会由两个不同的输出流来控制日志的写过程，分别为：EditLogFileOutputStream(本地输出流)和QuorumOutputStream(JN输出流)。写EditLog也不是直接写到磁盘中，为保证高吞吐，NameNode会分别为EditLogFileOutputStream和QuorumOutputStream定义两个同等大小的Buffer，大小大概是512KB，一个写Buffer(buffCurrent)，一个同步Buffer(buffReady)，这样可以一边写一边同步，所以EditLog是一个异步写过程，同时也是一个批量同步的过程，避免每写一笔就同步一次日志。</p>
<p>这个是怎么实现边写边同步的呢，这中间其实是有一个缓冲区交换的过程，即bufferCurrent和buffReady在达到条件时会触发交换，如bufferCurrent在达到阈值同时bufferReady的数据又同步完时，bufferReady数据会清空，同时会将bufferCurrent指针指向bufferReady以满足继续写，另外会将bufferReady指针指向bufferCurrent以提供继续同步EditLog。上面过程用流程图就是表示如下：<br><img src="/2019/07/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop%E4%BD%93%E7%B3%BB/hadoop/hadoop2.x%E6%9E%B6%E6%9E%84/1508123437957_9118_1508123462816.png" alt="image"></p>
<p>这里有一个问题，既然EditLog是异步写的，怎么保证缓存中的数据不丢呢,其实这里虽然是异步,但实际所有日志都需要通过logSync同步成功后才会给client返回成功码，假设某一时刻NameNode不可用了，其内存中的数据其实是未同步成功的，所以client会认为这部分数据未写成功。</p>
<p>第二个问题是，EditLog怎么在多个JN上保持一致的呢。下面展开介绍。</p>
<h5 id="隔离双写："><a href="#隔离双写：" class="headerlink" title="隔离双写："></a>隔离双写：</h5><p>在ANN每次同步EditLog到JN时，先要保证不会有两个NN同时向JN同步日志。这个隔离是怎么做的。这里面涉及一个很重要的概念Epoch Numbers，很多分布式系统都会用到。Epoch有如下几个特性：</p>
<ul>
<li>当NN成为活动结点时，其会被赋予一个EpochNumber</li>
<li>每个EpochNumber是惟一的，不会有相同的EpochNumber出现</li>
<li>EpochNumber有严格顺序保证，每次NN切换后其EpochNumber都会自增1，后面生成的EpochNumber都会大于前面的EpochNumber</li>
</ul>
<p>QJM是怎么保证上面特性的呢，主要有以下几点：</p>
<ul>
<li>第一步，在对EditLog作任何修改前，QuorumJournalManager(NameNode上)必须被赋予一个EpochNumber</li>
<li>第二步， QJM把自己的EpochNumber通过newEpoch(N)的方式发送给所有JN结点</li>
<li>第三步， 当JN收到newEpoch请求后，会把QJM的EpochNumber保存到一个lastPromisedEpoch变量中并持久化到本地磁盘</li>
<li>第四步， ANN同步日志到JN的任何RPC请求（如logEdits(),startLogSegment()等），都必须包含ANN的EpochNumber</li>
<li>第五步，JN在收到RPC请求后，会将之与lastPromisedEpoch对比，如果请求的EpochNumber小于lastPromisedEpoch,将会拒绝同步请求，反之，会接受同步请求并将请求的EpochNumber保存在lastPromisedEpoch</li>
</ul>
<blockquote>
<p>这样就能保证主备NN发生切换时，就算同时向JN同步日志，也能保证日志不会写乱，因为发生切换后，原ANN的EpochNumber肯定是小于新ANN的EpochNumber，所以原ANN向JN的发起的所有同步请求都会拒绝，实现隔离功能，防止了脑裂。</p>
</blockquote>
<h5 id="恢复in-process日志"><a href="#恢复in-process日志" class="headerlink" title="恢复in-process日志"></a>恢复in-process日志</h5><p>为什么要这步呢，如果在写过程中写失败了，可能各个JN上的EditLog的长度都不一样，需要在开始写之前将不一致的部分恢复。恢复机制如下：</p>
<ol>
<li>ANN先向所有JN发送getJournalState请求；</li>
<li>JN会向ANN返回一个Epoch（lastPromisedEpoch)；</li>
<li>ANN收到大多数JN的Epoch后，选择最大的一个并加1作为当前新的Epoch，然后向JN发送新的newEpoch请求，把新的Epoch下发给JN；</li>
<li>JN收到新的Epoch后，和lastPromisedEpoch对比，若更大则更新到本地并返回给ANN自己本地一个最新EditLogSegment起始事务Id,若小则返回NN错误；</li>
<li>ANN收到多数JN成功响应后认为Epoch生成成功，开始准备日志恢复；</li>
<li>ANN会选择一个最大的EditLogSegment事务ID作为恢复依据，然后向JN发送prepareRecovery； RPC请求，对应Paxos协议2p阶段的Phase1a，若多数JN响应prepareRecovery成功，则可认为Phase1a阶段成功；</li>
<li>ANN选择进行同步的数据源，向JN发送acceptRecovery RPC请求，并将数据源作为参数传给JN。</li>
<li>JN收到acceptRecovery请求后，会从JournalNodeHttpServer下载EditLogSegment并替换到本地保存的EditLogSegment，对应Paxos协议2p阶段的Phase1b，完成后返回ANN请求成功状态。</li>
<li>ANN收到多数JN的响应成功请求后，向JN发送finalizeLogSegment请求，表示数据恢复完成，这样之后所有JN上的日志就能保持一致。<br>数据恢复后，ANN上会将本地处于in-process状态的日志更名为finalized状态的日志，形式如<code>edits[start-txid][stop-txid]</code>。</li>
</ol>
<h5 id="日志同步"><a href="#日志同步" class="headerlink" title="日志同步"></a>日志同步</h5><p>这个步骤上面有介绍到关于日志从ANN同步到JN的过程,具体如下：</p>
<ol>
<li>执行logSync过程，将ANN上的日志数据放到缓存队列中</li>
<li>将缓存中数据同步到JN，JN有相应线程来处理logEdits请求</li>
<li>JN收到数据后，先确认EpochNumber是否合法，再验证日志事务ID是否正常，将日志刷到磁盘，返回ANN成功码</li>
<li>ANN收到JN成功请求后返回client写成功标识，若失败则抛出异常</li>
</ol>
<p>通过上面一些步骤，日志能保证成功同步到JN，同时保证JN日志的一致性，进而备NN上同步日志时也能保证数据是完整和一致的。</p>
<h4 id="QJM读过程分析"><a href="#QJM读过程分析" class="headerlink" title="QJM读过程分析"></a>QJM读过程分析</h4><p>这个读过程是面向备NN(SNN)的，SNN定期检查JournalNode上EditLog的变化，然后将EditLog拉回本地。SNN上有一个线程StandbyCheckpointer，会定期将SNN上FSImage和EditLog合并，并将合并完的FSImage文件传回主NN（ANN）上，就是所说的Checkpointing过程。下面我们来看下Checkpointing是怎么进行的。<br>在2.x版本中，已经将原来的由SecondaryNameNode主导的Checkpointing替换成由SNN主导的Checkpointing。下面是一个CheckPoint的流向图:<br><img src="/2019/07/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop%E4%BD%93%E7%B3%BB/hadoop/hadoop2.x%E6%9E%B6%E6%9E%84/1508123569245_7882_1508123594226.png" alt="image"></p>
<p>总的来说，就是在SNN上先检查前置条件，前置条件包括两个方面：距离上次Checkpointing的时间间隔和EditLog中事务条数限制。前置条件任何一个满足都会触发Checkpointing，然后SNN会将最新的NameSpace数据即SNN内存中当前状态的元数据保存到一个临时的fsimage文件( fsimage.ckpt）然后比对从JN上拉到的最新EditLog的事务ID，将fsimage.ckpt_中没有，EditLog中有的所有元数据修改记录合并一起并重命名成新的fsimage文件，同时生成一个md5文件。将最新的fsimage再通过HTTP请求传回ANN。通过定期合并fsimage有什么好处呢，主要有以下几个方面：</p>
<ul>
<li>可以避免EditLog越来越大，合并成新fsimage后可以将老的EditLog删除</li>
<li>可以避免主NN（ANN）压力过大，合并是在SNN上进行的</li>
<li>可以保证fsimage保存的是一份最新的元数据，故障恢复时避免数据丢失</li>
</ul>
<h2 id="主备切换机制"><a href="#主备切换机制" class="headerlink" title="主备切换机制"></a>主备切换机制</h2><p>要完成HA，除了元数据同步外，还得有一个完备的主备切换机制，Hadoop的主备选举依赖于ZooKeeper。下面是主备切换的状态图：<br><img src="/2019/07/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop%E4%BD%93%E7%B3%BB/hadoop/hadoop2.x%E6%9E%B6%E6%9E%84/1508123600971_8356_1508123625810.png" alt="image"></p>
<p>从图中可以看出，整个切换过程是由ZKFC来控制的，具体又可分为HealthMonitor、ZKFailoverController和ActiveStandbyElector三个组件。</p>
<ul>
<li>ZKFailoverController: 是HealthMontior和ActiveStandbyElector的母体，执行具体的切换操作</li>
<li>HealthMonitor: 监控NameNode健康状态，若状态异常会触发回调ZKFailoverController进行自动主备切换</li>
<li>ActiveStandbyElector: 通知ZK执行主备选举，若ZK完成变更，会回调ZKFailoverController相应方法进行主备状态切换</li>
</ul>
<p>在故障切换期间，ZooKeeper主要是发挥什么作用呢，有以下几点：</p>
<ul>
<li>失败保护：集群中每一个NameNode都会在ZooKeeper维护一个持久的session,机器一旦挂掉，session就会过期，故障迁移就会触发</li>
<li>Active NameNode选择：ZooKeeper有一个选择ActiveNN的机制，一旦现有的ANN宕机，其他NameNode可以向ZooKeeper申请排他成为下一个Active节点</li>
<li>防脑裂： ZK本身是强一致和高可用的，可以用它来保证同一时刻只有一个活动节点</li>
</ul>
<p>那在哪些场景会触发自动切换呢，从HDFS-2185中归纳了以下几个场景：</p>
<ul>
<li>ActiveNN JVM奔溃：ANN上HealthMonitor状态上报会有连接超时异常，HealthMonitor会触发状态迁移至SERVICE_NOT_RESPONDING, 然后ANN上的ZKFC会退出选举，SNN上的ZKFC会获得Active Lock, 作相应隔离后成为Active结点。</li>
<li>ActiveNN JVM冻结：这个是JVM没奔溃，但也无法响应，同奔溃一样，会触发自动切换。</li>
<li>ActiveNN 机器宕机：此时ActiveStandbyElector会失去同ZK的心跳，会话超时，SNN上的ZKFC会通知ZK删除ANN的活动锁，作相应隔离后完成主备切换。</li>
<li>ActiveNN 健康状态异常： 此时HealthMonitor会收到一个HealthCheckFailedException，并触发自动切换。</li>
<li>Active ZKFC奔溃：虽然ZKFC是一个独立的进程，但因设计简单也容易出问题，一旦ZKFC进程挂掉，虽然此时NameNode是OK的，但系统也认为需要切换，此时SNN会发一个请求到ANN要求ANN放弃主结点位置，ANN收到请求后，会触发完成自动切换。</li>
<li>ZooKeeper奔溃：如果ZK奔溃了，主备NN上的ZKFC都会感知断连，此时主备NN会进入一个NeutralMode模式，同时不改变主备NN的状态，继续发挥作用，只不过此时，如果ANN也故障了，那集群无法发挥Failover, 也就不可用了，所以对于此种场景，ZK一般是不允许挂掉到多台，至少要有N/2+1台保持服务才算是安全的。</li>
</ul>
</div><div class="tags"><a href="/tags/hadoop%E4%BD%93%E7%B3%BB/">hadoop体系</a></div><div class="post-nav"><a class="pre" href="/2019/07/16/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop%E4%BD%93%E7%B3%BB/hadoop/HDFS%E7%9A%84%E8%AF%BB%E5%86%99%E8%BF%87%E7%A8%8B/">HDFS的读写过程</a><a class="next" href="/2019/07/14/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/Kafka/kafka%20%E5%91%BD%E4%BB%A4/">kafka 命令</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://cunmin1718.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Beat/">Beat</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ES/">ES</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Elasticsearch/">Elasticsearch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kibana/">Kibana</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LVS/">LVS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Logstash/">Logstash</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Markdown/">Markdown</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NIFI/">NIFI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Nexus/">Nexus</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ansible/">ansible</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/drill/">drill</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ganglia/">ganglia</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/gitLab/">gitLab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/greenplum/">greenplum</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/greenplum/PostgreSQL/">PostgreSQL</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hbase/">hbase</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo/">hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hive/">hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/impala/">impala</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/k8s/">k8s</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kafka/">kafka</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/maven/">maven</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/oracle/">oracle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/scrapy/">scrapy</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/seaweed/">seaweed</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/zookeeper/">zookeeper</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/%E6%9D%82%E8%B0%88/" style="font-size: 15px;">杂谈</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size: 15px;">数据仓库</a> <a href="/tags/%E5%AE%B9%E5%99%A8/" style="font-size: 15px;">容器</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 15px;">数据库</a> <a href="/tags/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/" style="font-size: 15px;">项目开发</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 15px;">运维</a> <a href="/tags/ELK/" style="font-size: 15px;">ELK</a> <a href="/tags/hadoop%E4%BD%93%E7%B3%BB/" style="font-size: 15px;">hadoop体系</a> <a href="/tags/%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E/" style="font-size: 15px;">分析引擎</a> <a href="/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/" style="font-size: 15px;">文件存储</a> <a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15px;">消息队列</a> <a href="/tags/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/" style="font-size: 15px;">日志收集</a> <a href="/tags/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7/" style="font-size: 15px;">运维监控</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/02/26/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/nifi/NiFi%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97/">NiFi用户指南</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/20/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/nifi/nifi%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/">nifi组件介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E/greenplum/%E5%88%86%E5%8C%BA%E8%A1%A8/">分区表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/%E6%95%B0%E6%8D%AE%E5%BA%93/postgreSQL/PrepareStatement%E7%9A%84%E5%8A%9F%E4%B8%8E%E8%BF%87/">PrepareStatement的功与过</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/05/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E/greenplum/%E8%B5%84%E6%BA%90%E9%98%9F%E5%88%97%E7%AE%A1%E7%90%86/">资源队列管理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/30/python/python/Python%E5%B8%B8%E7%94%A8%E5%86%85%E5%BB%BA%E6%96%B9%E6%B3%95/">Python常用内建方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/29/python/python/args%E5%92%8Ckwargs%E7%9A%84%E5%8C%BA%E5%88%AB/">args和kwargs的区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/13/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E9%85%8D%E7%BD%AE/">redis配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/13/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E5%AE%89%E8%A3%85/">redis安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/12/python/scrapy/Middleware/HTTP%E7%BC%93%E5%AD%98%E4%B8%8E%E7%A6%BB%E7%BA%BF%E5%B7%A5%E4%BD%9C/">4. HTTP缓存与离线工作</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">记忆不靠谱.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>